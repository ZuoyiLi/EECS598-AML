{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "advmL_bayesian.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt30khjafzhC"
      },
      "source": [
        "# Bayesian Relevance\n",
        "Shrijesh Siwakoti\n",
        "\n",
        "Kevin Lee\n",
        "\n",
        "Ananth Chillarige"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FBDDOWdhJX7"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFbFTi9vfpOI"
      },
      "source": [
        "#### 1. Load Google Drive Storage Work Space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53Ne9TgI66KG",
        "outputId": "9181535d-b9a6-43c9-8ac2-c85f2b06090b"
      },
      "source": [
        "%cd \"/content/drive/MyDrive/EECS 598 Adv. ML/Shrijesh\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1jgtlMlObkEDJskwSwPdeQSDe5B234rbW/EECS 598 Adv. ML/Shrijesh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNpdphltgNOc"
      },
      "source": [
        "#### 2. Clone BayesianRelevance and DeepRobust Repos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J54-BE61Yw8",
        "outputId": "4b0a9e6f-d30d-48bb-907d-242547897453"
      },
      "source": [
        "!git clone https://github.com/ssiwakot/BayesianRelevance.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BayesianRelevance'...\n",
            "remote: Enumerating objects: 118, done.\u001b[K\n",
            "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 1638 (delta 49), reused 79 (delta 22), pack-reused 1520\u001b[K\n",
            "Receiving objects: 100% (1638/1638), 59.45 MiB | 20.41 MiB/s, done.\n",
            "Resolving deltas: 100% (1243/1243), done.\n",
            "Checking out files: 100% (78/78), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SEqkUuqEm0D",
        "outputId": "15216620-3d1b-4b03-8c4a-c2ebad242f9b"
      },
      "source": [
        "!git clone https://github.com/ssiwakot/DeepRobust.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepRobust'...\n",
            "remote: Enumerating objects: 575, done.\u001b[K\n",
            "remote: Counting objects: 100% (575/575), done.\u001b[K\n",
            "remote: Compressing objects: 100% (380/380), done.\u001b[K\n",
            "remote: Total 4863 (delta 360), reused 349 (delta 192), pack-reused 4288\u001b[K\n",
            "Receiving objects: 100% (4863/4863), 11.09 MiB | 9.35 MiB/s, done.\n",
            "Resolving deltas: 100% (3223/3223), done.\n",
            "Checking out files: 100% (369/369), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TZIMtIRgbhv"
      },
      "source": [
        "#### 3. Install DeepRobust Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1csCzwsFZd6",
        "outputId": "c3ae670a-9e2d-4b8b-8071-7ad914452b53"
      },
      "source": [
        "!pip install DeepRobust/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./DeepRobust\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from deeprobust==0.1.0) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.1 in /usr/local/lib/python3.7/dist-packages (from deeprobust==0.1.0) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from deeprobust==0.1.0) (1.8.1+cu101)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from deeprobust==0.1.0) (1.4.1)\n",
            "Requirement already satisfied: torchvision>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from deeprobust==0.1.0) (0.9.1+cu101)\n",
            "Collecting texttable>=1.6.2\n",
            "  Downloading https://files.pythonhosted.org/packages/06/f5/46201c428aebe0eecfa83df66bf3e6caa29659dbac5a56ddfd83cae0d4a4/texttable-1.6.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.7/dist-packages (from deeprobust==0.1.0) (2.5.1)\n",
            "Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.7/dist-packages (from deeprobust==0.1.0) (0.51.2)\n",
            "Requirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from deeprobust==0.1.0) (7.1.2)\n",
            "Requirement already satisfied: scikit_learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from deeprobust==0.1.0) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image>=0.0 in /usr/local/lib/python3.7/dist-packages (from deeprobust==0.1.0) (0.16.2)\n",
            "Collecting tensorboardX>=2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 25.6MB/s \n",
            "\u001b[?25hCollecting tqdm>=4.42.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/8a/34efae5cf9924328a8f34eeb2fdaae14c011462d9f0e3fcded48e1266d1c/tqdm-4.60.0-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.6MB/s \n",
            "\u001b[?25hCollecting gensim<4.0,>=3.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/afe2315e08a38967f8a3036bbe7e38b428e9b7a90e823a83d0d49df1adf5/gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 62.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->deeprobust==0.1.0) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->deeprobust==0.1.0) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->deeprobust==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->deeprobust==0.1.0) (0.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2.0->deeprobust==0.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.4->deeprobust==0.1.0) (4.4.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->deeprobust==0.1.0) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->deeprobust==0.1.0) (56.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>=0.22.1->deeprobust==0.1.0) (1.0.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.0->deeprobust==0.1.0) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.0->deeprobust==0.1.0) (2.4.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=2.0->deeprobust==0.1.0) (3.12.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0,>=3.8->deeprobust==0.1.0) (5.0.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0,>=3.8->deeprobust==0.1.0) (1.15.0)\n",
            "Building wheels for collected packages: deeprobust\n",
            "  Building wheel for deeprobust (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deeprobust: filename=deeprobust-0.1.0-cp37-none-any.whl size=1139257 sha256=2e94e9d687cd39db077a9bce29a52914d0b5ea646b7cf752b3a1ab7283dd9cc1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fq86nfo7/wheels/9c/0f/7c/41ff00faaa1b28e85f09efdb0158bc57ea493a1ab590b82895\n",
            "Successfully built deeprobust\n",
            "Installing collected packages: texttable, tensorboardX, tqdm, gensim, deeprobust\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed deeprobust-0.1.0 gensim-3.8.3 tensorboardX-2.2 texttable-1.6.3 tqdm-4.60.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z84trYwgzmN"
      },
      "source": [
        "#### 4. Setup environment and required packages for Bayesian Relevance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2waxD81LlAf",
        "outputId": "242d2b10-42ac-4d60-b3e6-b9f67412bb7e"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1jgtlMlObkEDJskwSwPdeQSDe5B234rbW/EECS 598 Adv. ML/Shrijesh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7nTpmq4U1on-",
        "outputId": "da2545af-da8b-4bbb-dbd1-df409600beec"
      },
      "source": [
        "%cd BayesianRelevance/ \n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1jgtlMlObkEDJskwSwPdeQSDe5B234rbW/EECS 598 Adv. ML/Shrijesh/BayesianRelevance\n",
            "Collecting absl-py==0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 17.0MB/s \n",
            "\u001b[?25hCollecting appdirs==1.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n",
            "Collecting asn1crypto==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/8c/ff300484eca90b397d919408619fae479965bdd8a1df3d6d08d58e491da5/asn1crypto-1.2.0-py2.py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 33.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.8.1)\n",
            "Requirement already satisfied: blis==0.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: catalogue==1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.0.0)\n",
            "Collecting certifi==2019.11.28\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl (156kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 47.9MB/s \n",
            "\u001b[?25hCollecting cffi==1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/20/b93b26ad86f48403144823f521aa571a71e61575863a260cca2918ec3881/cffi-1.13.0-cp37-cp37m-manylinux1_x86_64.whl (430kB)\n",
            "\u001b[K     |████████████████████████████████| 440kB 50.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (3.0.4)\n",
            "Collecting cryptography==2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/9a/7cece52c46546e214e10811b36b2da52ce1ea7fa203203a629b8dfadad53/cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 54.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.10.0)\n",
            "Collecting cymem==2.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/93/d63c12f492cd9e463e67554fd187adce4efc94451aca1f825caf2f310140/cymem-2.0.4-cp37-cp37m-manylinux2014_x86_64.whl\n",
            "Collecting dataclasses==0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (4.4.2)\n",
            "Collecting distlib==0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/29/694a3a4d7c0e1aef76092e9167fbe372e0f7da055f5dcf4e1313ec21d96a/distlib-0.3.0.zip (571kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 51.5MB/s \n",
            "\u001b[?25hCollecting eagerpy==0.27.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/4c/13ed2aba954c111ea0aff7e75a5e3c95b533504ba24718f7ea18b036c440/eagerpy-0.27.0-py3-none-any.whl\n",
            "Collecting fastai==2.1.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/04/73437c9781274b3dea0d7b039c365c5b140ce47889e47609eedd2c5f7b3d/fastai-2.1.7-py3-none-any.whl (189kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 57.1MB/s \n",
            "\u001b[?25hCollecting fastcore==1.3.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/6b/9e9913cdce0894f15535e1eb92693de7a5d1897002d922232b5385778f4b/fastcore-1.3.7-py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: fastprogress==1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (1.0.0)\n",
            "Requirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (3.0.12)\n",
            "Collecting foolbox==3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/9e/c629bd79655fc2052102912eb6b00dc553f0acefbcdc6700b56811fe77fb/foolbox-3.0.0.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 41.2MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting future==0.18.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 32.5MB/s \n",
            "\u001b[?25hCollecting gast==0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/04/4e36c33f8eb5c5b6c622a1f4859352a6acca7ab387257d4b3c191d23ec1d/gast-0.3.2.tar.gz\n",
            "Collecting gitdb==4.0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.8MB/s \n",
            "\u001b[?25hCollecting GitPython==3.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/33/917e6fde1cad13daa7053f39b7c8af3be287314f75f1b1ea8d3fe37a8571/GitPython-3.1.2-py3-none-any.whl (451kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 53.8MB/s \n",
            "\u001b[?25hCollecting grpcio==1.26.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/b3/0052e38c640d52b710e235b15821cc3c61d0065bf54e70a44550ef127349/grpcio-1.26.0-cp37-cp37m-manylinux2010_x86_64.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 104kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 27)) (2.10.0)\n",
            "Collecting idna==2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.4MB/s \n",
            "\u001b[?25hCollecting imageio==2.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 49.4MB/s \n",
            "\u001b[?25hCollecting importlib-metadata==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8b/03/a00d504808808912751e64ccf414be53c29cad620e3de2421135fcae3025/importlib_metadata-1.5.0-py2.py3-none-any.whl\n",
            "Collecting joblib==0.14.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 55.5MB/s \n",
            "\u001b[?25hCollecting Keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 40.1MB/s \n",
            "\u001b[?25hCollecting Keras-Applications==1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hCollecting Keras-Preprocessing==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.4MB/s \n",
            "\u001b[?25hCollecting kiwisolver==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/f8/518fb0bb89860eea6ff1b96483fbd9236d5ee991485d0f3eceff1770f654/kiwisolver-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.9MB/s \n",
            "\u001b[?25hCollecting llvmlite==0.35.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/9e/3b6283c1c074bedc96df7741b04d3c2def90dc7f4e99442e127676c953ec/llvmlite-0.35.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3MB 131kB/s \n",
            "\u001b[?25hCollecting Markdown==3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.3MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/f2/10c822cb0ca5ebec58bd1892187bc3e3db64a867ac26531c6204663fc218/matplotlib-3.3.3-cp37-cp37m-manylinux1_x86_64.whl (11.6MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6MB 28.7MB/s \n",
            "\u001b[?25hCollecting mock==3.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
            "Collecting murmurhash==1.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/ce/0e50d297db528d94541b9e593d3cbd4a9d3869b78561a0454c41b9397658/murmurhash-1.0.4-cp37-cp37m-manylinux2014_x86_64.whl\n",
            "Collecting networkx==2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/cd/dc52755d30ba41c60243235460961fc28022e5b6731f16c268667625baea/networkx-2.5-py3-none-any.whl (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 49.4MB/s \n",
            "\u001b[?25hCollecting numba==0.52.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/ae/207305b9f2e7468fc9d46d5277d84b758bdee70debdbed9f3ac9c978ca9f/numba-0.52.0-cp37-cp37m-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 42.2MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/0c/0261693cc3ad8e2b66e66dc2d2676a2cc17d3efb1c58a70db73754320e47/numpy-1.18.1-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 13.4MB/s \n",
            "\u001b[?25hCollecting opt-einsum==3.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/49/2233e63052d5686c72131b579837ddfb98ba9dd0b92bb91efcb441ada8ce/opt_einsum-3.2.0-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.6MB/s \n",
            "\u001b[?25hCollecting packaging==20.4\n",
            "  Downloading https://files.pythonhosted.org/packages/46/19/c5ab91b1b05cfe63cccd5cfc971db9214c6dd6ced54e33c30d5af1d2bc43/packaging-20.4-py2.py3-none-any.whl\n",
            "Collecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/e0/a1b39cdcb2c391f087a1538bc8a6d62a82d0439693192aef541d7b123769/pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 44.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: patsy==0.5.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 47)) (0.5.1)\n",
            "Collecting Pillow==8.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/fa/c1302a26d5e1a17fa8e10e43417b6cf038b0648c4b79fcf2302a4a0c5d30/Pillow-8.0.1-cp37-cp37m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 48.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: plac==1.1.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 49)) (1.1.3)\n",
            "Collecting preshed==3.0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/14/7ea5a980306382410968cf29dd24670657d42c631201c945c320f997bdd1/preshed-3.0.4-cp37-cp37m-manylinux2014_x86_64.whl (284kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 61.6MB/s \n",
            "\u001b[?25hCollecting protobuf==3.11.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/14/f5c294f1e36a031f165128c25feba93b3116f15a74398d0b2747ed75744f/protobuf-3.11.2-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 57.2MB/s \n",
            "\u001b[?25hCollecting psutil==5.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/da/f7efdcf012b51506938553dbe302aecc22f3f43abd5cffa8320e8e0588d5/psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 56.7MB/s \n",
            "\u001b[?25hCollecting pycosat==0.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/fd/e38d68774c0a345b0090d608a90f1fbf423970d812f7ec7aef9ac024e648/pycosat-0.6.3.zip (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.2MB/s \n",
            "\u001b[?25hCollecting pycparser==2.19\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/9e/49196946aee219aead1290e00d1e7fdeab8567783e83e1b9ab5585e6206a/pycparser-2.19.tar.gz (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 46.4MB/s \n",
            "\u001b[?25hCollecting pyOpenSSL==19.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/c8/ceb170d81bd3941cbeb9940fc6cc2ef2ca4288d0ca8929ea4db5905d904d/pyOpenSSL-19.0.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.2MB/s \n",
            "\u001b[?25hCollecting pyparsing==2.4.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/bc/1e58593167fade7b544bfe9502a26dc860940a79ab306e651e7f13be68c2/pyparsing-2.4.6-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.9MB/s \n",
            "\u001b[?25hCollecting pyro-api==0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/bc/6cdbd1929e32fff62a33592633c2cc0393c7f7739131ccc9c9c4e28ac8dd/pyro_api-0.1.1-py3-none-any.whl\n",
            "Collecting pyro-ppl==1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/97/42073ec6cc550f6bf1e3982ded454500c657ee2a3fd2dd6886984c8d4ca2/pyro_ppl-1.3.0-py3-none-any.whl (495kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 57.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: PySocks==1.7.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 59)) (1.7.1)\n",
            "Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 60)) (2.8.1)\n",
            "Collecting pytz==2019.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 60.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyWavelets==1.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 62)) (1.1.1)\n",
            "Collecting PyYAML==5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/d9/ea9816aea31beeadccd03f1f8b625ecf8f645bd66744484d162d84803ce5/PyYAML-5.3.tar.gz (268kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 60.5MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.5MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml==0.15.46\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/8b/523140adb2b21c757282df0be91929e6696deec04b27443923137da80692/ruamel.yaml-0.15.46-cp37-cp37m-manylinux1_x86_64.whl (632kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 57.3MB/s \n",
            "\u001b[?25hCollecting scikit-image==0.18.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/01/3a830f3df578ea3ed94ee7fd9f91e85c3dec2431d8548ab1c91869e51450/scikit_image-0.18.1-cp37-cp37m-manylinux1_x86_64.whl (29.2MB)\n",
            "\u001b[K     |████████████████████████████████| 29.2MB 105kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn==0.22.2.post1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 67)) (0.22.2.post1)\n",
            "Collecting scipy==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/39/066ecde98f373430bf7a39a02d91c7075b01ef4fc928456e8e31577342d6/scipy-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (26.6MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6MB 80kB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn==0.11.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 69)) (0.11.1)\n",
            "Collecting six==1.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
            "Collecting smmap==3.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Collecting spacy==2.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/24/70c615f5b22440c679a4132b81eee67d1dfd70d159505a28ff949c78a1ac/spacy-2.3.2-cp37-cp37m-manylinux1_x86_64.whl (9.9MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9MB 30.1MB/s \n",
            "\u001b[?25hCollecting srsly==1.0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/00/cb908056dbc796f2f68b80e9a8cf5119103c685a26ecbbcf474a6de25f56/srsly-1.0.4-cp37-cp37m-manylinux2014_x86_64.whl (293kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 54.2MB/s \n",
            "\u001b[?25hCollecting statsmodels==0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/cb/614f37ac4a9919eb0dbc0cd9eb939d1a33299f54f10e8a705dd9b08c2f3f/statsmodels-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (8.1MB)\n",
            "\u001b[K     |████████████████████████████████| 8.1MB 47.5MB/s \n",
            "\u001b[?25hCollecting tensorboard==1.12.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 45.9MB/s \n",
            "\u001b[?25hCollecting tensorboardX==2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 40.0MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.13.0rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/80/18adfb46ba0a4044e9feaa0897ceae4673ac07d34deeb74490bc0d4e4987/tensorflow-1.13.0rc1-cp37-cp37m-manylinux1_x86_64.whl (92.7MB)\n",
            "\u001b[K     |████████████████████████████████| 92.7MB 1.5MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 43.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 79)) (1.1.0)\n",
            "Requirement already satisfied: texttable==1.6.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 80)) (1.6.3)\n",
            "Collecting thinc==7.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/4e/6f16cfebb0dd68cc8a9a973eba8e01ee7b960dc563edb12a3ee397473e32/thinc-7.4.1-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 46.2MB/s \n",
            "\u001b[?25hCollecting tifffile==2020.12.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/ee/63c1314e5e2d8ff59b5afffb13ea245c65ce796bda4feacc7013ea4a300b/tifffile-2020.12.8-py3-none-any.whl (157kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 57.7MB/s \n",
            "\u001b[?25hCollecting torch==1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/74/d52c014fbfb50aefc084d2bf5ffaa0a8456f69c586782b59f93ef45e2da9/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 24kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/39/a9caac0deb027feec2cdd7cc40b2a598256d3f50050c80f349c030f915f2/torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7MB 82kB/s \n",
            "\u001b[?25hCollecting tornado==6.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/78/2d2823598496127b21423baffaa186b668f73cd91887fcef78b6eade136b/tornado-6.0.3.tar.gz (482kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 56.9MB/s \n",
            "\u001b[?25hCollecting tqdm==4.53.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/bc/857fff709f7ce9eabdc502d6fa71f4b7e964200b1bcd00f0a2f59667d1bf/tqdm-4.53.0-py2.py3-none-any.whl (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.6MB/s \n",
            "\u001b[?25hCollecting typing-extensions==3.7.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/0e/3f026d0645d699e7320b59952146d56ad7c374e9cd72cd16e7c74e657a0f/typing_extensions-3.7.4.2-py3-none-any.whl\n",
            "Collecting urllib3==1.24.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/1c/59cca3abf96f991f2ec3131a4ffe72ae3d9ea1f5894abe8a9c5e3c77cfee/urllib3-1.24.2-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 55.5MB/s \n",
            "\u001b[?25hCollecting virtualenv==20.0.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/9a/d5b295801f94bbc8c6e575563b87ae38dc2ebeb52f93cc4c070ab3836fe8/virtualenv-20.0.14-py2.py3-none-any.whl (4.6MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6MB 43.6MB/s \n",
            "\u001b[?25hCollecting wasabi==0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/10/55f3cf6b52cc89107b3e1b88fcf39719392b377a3d78ca61da85934d0d10/wasabi-0.8.0-py3-none-any.whl\n",
            "Requirement already satisfied: Werkzeug==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 91)) (1.0.1)\n",
            "Collecting zipp==3.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/34/bfcb43cc0ba81f527bc4f40ef41ba2ff4080e047acb0586b56b3d017ace4/zipp-3.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai==2.1.7->-r requirements.txt (line 17)) (19.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from foolbox==3.0.0->-r requirements.txt (line 21)) (56.0.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.12.2->-r requirements.txt (line 75)) (0.36.2)\n",
            "Building wheels for collected packages: foolbox\n",
            "  Building wheel for foolbox (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for foolbox: filename=foolbox-3.0.0-cp37-none-any.whl size=1654121 sha256=f51d44a4b1da3f6c20135b39442d24512216ee13de1c5e7aedc74362379af3c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/0f/10/8e0ad204b31ae13d9a2f7d5dec988b8adcd5fd7a9870680866\n",
            "Successfully built foolbox\n",
            "Building wheels for collected packages: absl-py, distlib, future, gast, pycosat, pycparser, PyYAML, tornado\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for absl-py: filename=absl_py-0.9.0-cp37-none-any.whl size=121931 sha256=d541fb66b4a3af3f762f69ce0af21ecc4e3722fdb640f7d46aba912f20365e19\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
            "  Building wheel for distlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distlib: filename=distlib-0.3.0-cp37-none-any.whl size=340429 sha256=5f3261c5d2b64446b584777b5c992880cae6ba729c270998cfdc2ea378576bdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/e8/db/c73dae4867666e89ba3cfbc4b5c092446f0e584eda6f409cbb\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=2c8583832d654328af5151b7c642f9ac047b1f9233904186c78c1377cbadd453\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.3.2-cp37-none-any.whl size=9678 sha256=a067bee16f1946c33eec586ebd6c79428a71838d27dac08b96e87653b93625ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/38/c6/234dc39b4f6951a0768fbc02d5b7207137a5b1d9094f0d54bf\n",
            "  Building wheel for pycosat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycosat: filename=pycosat-0.6.3-cp37-cp37m-linux_x86_64.whl size=143811 sha256=e40120ee291bd6bb2125b600466624c6717beac67d497c46e880ede06d516d86\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/67/ff/5570304e45814eccef48a3c69c3af25d0456ed3a34eddbbe38\n",
            "  Building wheel for pycparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycparser: filename=pycparser-2.19-py2.py3-none-any.whl size=111031 sha256=7d39af8a07012ae48753c88ec6577c8f40976d05bfd75393be75dcdf9f425c67\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/9a/90/de94f8556265ddc9d9c8b271b0f63e57b26fb1d67a45564511\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3-cp37-cp37m-linux_x86_64.whl size=44228 sha256=aea02e21b6967cc9c9ac1ca1e0225be821da4dff74b7ffdce23172051bf1af4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/76/4d/a95b8dd7b452b69e8ed4f68b69e1b55e12c9c9624dd962b191\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-6.0.3-cp37-cp37m-linux_x86_64.whl size=424109 sha256=942d8ddc457a12d8ce34c16546e03ddb66e9517f2f87030a68918180c461bd44\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/bf/40/2f6ef700f48401ca40e5e3dd7d0e3c0a90e064897b7fe5fc08\n",
            "Successfully built absl-py distlib future gast pycosat pycparser PyYAML tornado\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: googleapis-common-protos 1.53.0 has requirement protobuf>=3.12.0, but you'll have protobuf 3.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= \"3.0\", but you'll have tornado 6.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-python-client 1.12.8 has requirement six<2dev,>=1.13.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-core 1.26.3 has requirement protobuf>=3.12.0, but you'll have protobuf 3.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-core 1.26.3 has requirement six>=1.13.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: deeprobust 0.1.0 has requirement scipy>=1.3.1, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, absl-py, appdirs, asn1crypto, certifi, pycparser, cffi, cryptography, cymem, dataclasses, distlib, typing-extensions, numpy, eagerpy, kiwisolver, pyparsing, Pillow, matplotlib, idna, urllib3, requests, murmurhash, preshed, tqdm, srsly, wasabi, thinc, spacy, future, torch, packaging, torchvision, fastcore, PyYAML, pytz, pandas, scipy, fastai, smmap, gitdb, GitPython, foolbox, gast, grpcio, imageio, zipp, importlib-metadata, joblib, Keras-Applications, Keras-Preprocessing, Keras, llvmlite, Markdown, mock, networkx, numba, opt-einsum, protobuf, psutil, pycosat, pyOpenSSL, pyro-api, pyro-ppl, ruamel.yaml, tifffile, scikit-image, statsmodels, tensorboard, tensorboardX, tensorflow-estimator, tensorflow, tornado, virtualenv\n",
            "  Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Found existing installation: absl-py 0.12.0\n",
            "    Uninstalling absl-py-0.12.0:\n",
            "      Successfully uninstalled absl-py-0.12.0\n",
            "  Found existing installation: appdirs 1.4.4\n",
            "    Uninstalling appdirs-1.4.4:\n",
            "      Successfully uninstalled appdirs-1.4.4\n",
            "  Found existing installation: certifi 2020.12.5\n",
            "    Uninstalling certifi-2020.12.5:\n",
            "      Successfully uninstalled certifi-2020.12.5\n",
            "  Found existing installation: pycparser 2.20\n",
            "    Uninstalling pycparser-2.20:\n",
            "      Successfully uninstalled pycparser-2.20\n",
            "  Found existing installation: cffi 1.14.5\n",
            "    Uninstalling cffi-1.14.5:\n",
            "      Successfully uninstalled cffi-1.14.5\n",
            "  Found existing installation: cymem 2.0.5\n",
            "    Uninstalling cymem-2.0.5:\n",
            "      Successfully uninstalled cymem-2.0.5\n",
            "  Found existing installation: typing-extensions 3.7.4.3\n",
            "    Uninstalling typing-extensions-3.7.4.3:\n",
            "      Successfully uninstalled typing-extensions-3.7.4.3\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: kiwisolver 1.3.1\n",
            "    Uninstalling kiwisolver-1.3.1:\n",
            "      Successfully uninstalled kiwisolver-1.3.1\n",
            "  Found existing installation: pyparsing 2.4.7\n",
            "    Uninstalling pyparsing-2.4.7:\n",
            "      Successfully uninstalled pyparsing-2.4.7\n",
            "  Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: murmurhash 1.0.5\n",
            "    Uninstalling murmurhash-1.0.5:\n",
            "      Successfully uninstalled murmurhash-1.0.5\n",
            "  Found existing installation: preshed 3.0.5\n",
            "    Uninstalling preshed-3.0.5:\n",
            "      Successfully uninstalled preshed-3.0.5\n",
            "  Found existing installation: tqdm 4.60.0\n",
            "    Uninstalling tqdm-4.60.0:\n",
            "      Successfully uninstalled tqdm-4.60.0\n",
            "  Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Found existing installation: wasabi 0.8.2\n",
            "    Uninstalling wasabi-0.8.2:\n",
            "      Successfully uninstalled wasabi-0.8.2\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: packaging 20.9\n",
            "    Uninstalling packaging-20.9:\n",
            "      Successfully uninstalled packaging-20.9\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: grpcio 1.32.0\n",
            "    Uninstalling grpcio-1.32.0:\n",
            "      Successfully uninstalled grpcio-1.32.0\n",
            "  Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Found existing installation: zipp 3.4.1\n",
            "    Uninstalling zipp-3.4.1:\n",
            "      Successfully uninstalled zipp-3.4.1\n",
            "  Found existing installation: importlib-metadata 3.10.1\n",
            "    Uninstalling importlib-metadata-3.10.1:\n",
            "      Successfully uninstalled importlib-metadata-3.10.1\n",
            "  Found existing installation: joblib 1.0.1\n",
            "    Uninstalling joblib-1.0.1:\n",
            "      Successfully uninstalled joblib-1.0.1\n",
            "  Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "  Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Found existing installation: Markdown 3.3.4\n",
            "    Uninstalling Markdown-3.3.4:\n",
            "      Successfully uninstalled Markdown-3.3.4\n",
            "  Found existing installation: networkx 2.5.1\n",
            "    Uninstalling networkx-2.5.1:\n",
            "      Successfully uninstalled networkx-2.5.1\n",
            "  Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Found existing installation: opt-einsum 3.3.0\n",
            "    Uninstalling opt-einsum-3.3.0:\n",
            "      Successfully uninstalled opt-einsum-3.3.0\n",
            "  Found existing installation: protobuf 3.12.4\n",
            "    Uninstalling protobuf-3.12.4:\n",
            "      Successfully uninstalled protobuf-3.12.4\n",
            "  Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Found existing installation: tifffile 2021.4.8\n",
            "    Uninstalling tifffile-2021.4.8:\n",
            "      Successfully uninstalled tifffile-2021.4.8\n",
            "  Found existing installation: scikit-image 0.16.2\n",
            "    Uninstalling scikit-image-0.16.2:\n",
            "      Successfully uninstalled scikit-image-0.16.2\n",
            "  Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorboardX 2.2\n",
            "    Uninstalling tensorboardX-2.2:\n",
            "      Successfully uninstalled tensorboardX-2.2\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "  Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "Successfully installed GitPython-3.1.2 Keras-2.3.1 Keras-Applications-1.0.8 Keras-Preprocessing-1.1.0 Markdown-3.1.1 Pillow-8.0.1 PyYAML-5.3 absl-py-0.9.0 appdirs-1.4.3 asn1crypto-1.2.0 certifi-2019.11.28 cffi-1.13.0 cryptography-2.8 cymem-2.0.4 dataclasses-0.6 distlib-0.3.0 eagerpy-0.27.0 fastai-2.1.7 fastcore-1.3.7 foolbox-3.0.0 future-0.18.2 gast-0.3.2 gitdb-4.0.5 grpcio-1.26.0 idna-2.8 imageio-2.9.0 importlib-metadata-1.5.0 joblib-0.14.1 kiwisolver-1.1.0 llvmlite-0.35.0 matplotlib-3.3.3 mock-3.0.5 murmurhash-1.0.4 networkx-2.5 numba-0.52.0 numpy-1.18.1 opt-einsum-3.2.0 packaging-20.4 pandas-0.25.3 preshed-3.0.4 protobuf-3.11.2 psutil-5.8.0 pyOpenSSL-19.0.0 pycosat-0.6.3 pycparser-2.19 pyparsing-2.4.6 pyro-api-0.1.1 pyro-ppl-1.3.0 pytz-2019.3 requests-2.22.0 ruamel.yaml-0.15.46 scikit-image-0.18.1 scipy-1.2.0 six-1.12.0 smmap-3.0.4 spacy-2.3.2 srsly-1.0.4 statsmodels-0.10.1 tensorboard-1.12.2 tensorboardX-2.1 tensorflow-1.13.0rc1 tensorflow-estimator-1.13.0 thinc-7.4.1 tifffile-2020.12.8 torch-1.7.0 torchvision-0.8.1 tornado-6.0.3 tqdm-4.53.0 typing-extensions-3.7.4.2 urllib3-1.24.2 virtualenv-20.0.14 wasabi-0.8.0 zipp-3.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "cffi",
                  "google",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pandas",
                  "psutil",
                  "pyparsing",
                  "pytz",
                  "six",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2AnNLCAiJcX",
        "outputId": "42feef19-c3c3-4964-df1c-5a06b86fe4ef"
      },
      "source": [
        "%cd BayesianRelevance/ "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1jgtlMlObkEDJskwSwPdeQSDe5B234rbW/EECS 598 Adv. ML/Shrijesh/BayesianRelevance\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lbU3EmG3QpI",
        "outputId": "907d5631-ce27-4e7c-ddd6-fc9684c721a8"
      },
      "source": [
        "%cd src"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1jgtlMlObkEDJskwSwPdeQSDe5B234rbW/EECS 598 Adv. ML/Shrijesh/BayesianRelevance/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWO1nvOOhP7W"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvAIrELjhBQ3"
      },
      "source": [
        "#### 1. Train Base NN Model on MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeHR-v6iD4YU",
        "outputId": "99a33990-a5b8-4e05-a09b-ebe9835eafb1"
      },
      "source": [
        "!python train_networks.py --model=baseNN --model_idx=0"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "PyTorch Version:  1.7.0\n",
            "\n",
            "Loading mnist.\n",
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape = torch.Size([60000, 1, 28, 28]) \n",
            "x_test shape = torch.Size([10000, 1, 28, 28])\n",
            "y_train shape = torch.Size([60000, 10]) \n",
            "y_test shape = torch.Size([10000, 10])\n",
            "\n",
            "baseNN total number of weights = 456618\n",
            "\n",
            " == baseNN training ==\n",
            "\n",
            "[Epoch 1]\t loss: 0.00126569 \t accuracy: 95.21\t\n",
            "[Epoch 2]\t loss: 0.00033543 \t accuracy: 98.69\t\n",
            "[Epoch 3]\t loss: 0.00021994 \t accuracy: 99.07\t\n",
            "[Epoch 4]\t loss: 0.00016076 \t accuracy: 99.34\t\n",
            "[Epoch 5]\t loss: 0.00012508 \t accuracy: 99.48\t\n",
            "Execution time = 00:00:25\n",
            "\n",
            "Accuracy: 99.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoBcMnNShGzm"
      },
      "source": [
        "#### 2. Train Bayesian NN on MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjvNEvgDiqHE",
        "outputId": "3296d646-ba9d-4781-bcb5-29745dca2037"
      },
      "source": [
        "!python train_networks.py --model=fullBNN --model_idx=0"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "PyTorch Version:  1.7.0\n",
            "\n",
            "Loading mnist.\n",
            "x_train shape = torch.Size([60000, 1, 28, 28]) \n",
            "x_test shape = torch.Size([10000, 1, 28, 28])\n",
            "y_train shape = torch.Size([60000, 10]) \n",
            "y_test shape = torch.Size([10000, 10])\n",
            "\n",
            "baseNN total number of weights = 456618\n",
            "\n",
            " == fullBNN SVI training ==\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/primitives.py:406: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n",
            "\n",
            "[Epoch 1]\t loss: 7958.80 \t accuracy: 41.40\t\n",
            "[Epoch 2]\t loss: 3649.54 \t accuracy: 66.14\t\n",
            "[Epoch 3]\t loss: 3161.64 \t accuracy: 72.50\t\n",
            "[Epoch 4]\t loss: 2814.94 \t accuracy: 75.94\t\n",
            "[Epoch 5]\t loss: 2495.50 \t accuracy: 77.95\t\n",
            "Execution time = 00:00:55\n",
            "\n",
            "learned params = dict_keys(['model.0.weight_loc', 'model.0.weight_scale', 'model.0.bias_loc', 'model.0.bias_scale', 'model.3.weight_loc', 'model.3.weight_scale', 'model.3.bias_loc', 'model.3.bias_scale', 'model.7.weight_loc', 'model.7.weight_scale', 'model.7.bias_loc', 'model.7.bias_scale'])\n",
            "\n",
            "Saving:  ../experiments/fullBNN/mnist_conv_idx=0/mnist_fullBNN_svi_hid=512_act=leaky_arch=conv_ep=5_lr=0.01_weights.pt\n",
            "Accuracy: 90.22%\n",
            "Accuracy: 91.35%\n",
            "Accuracy: 92.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2w2uuebhlhr"
      },
      "source": [
        "### FGSM Attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPvc43VUhpvV"
      },
      "source": [
        "#### 1. FGSM attack on Base NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9HKn9gMl2Ol",
        "outputId": "25616576-3caa-48cb-bf6d-70a119197bca"
      },
      "source": [
        "!python attack_networks.py --model=baseNN --model_idx=0 \\\n",
        "\t\t--attack_method=fgsm --n_inputs=500"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "PyTorch Version:  1.7.0\n",
            "\n",
            "Loading mnist.\n",
            "x_train shape = torch.Size([500, 1, 28, 28]) \n",
            "x_test shape = torch.Size([500, 1, 28, 28])\n",
            "y_train shape = torch.Size([500, 10]) \n",
            "y_test shape = torch.Size([500, 10])\n",
            "\n",
            "baseNN total number of weights = 456618\n",
            "\n",
            "\n",
            "Crafting fgsm attacks\n",
            "100% 500/500 [00:01<00:00, 417.23it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/attacks/fgsm_attack.pkl\n",
            "\n",
            "Evaluating against the attacks\n",
            "test accuracy = 98.6\tadversarial accuracy = 29.6\tavg softmax robustness = 0.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89c2kZYZiQdB"
      },
      "source": [
        "#### 2. FGSM attack on Bayesian NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Yoci5aW30WQ",
        "outputId": "fa7ba9c5-e68a-4b33-a732-ed0d0535094f"
      },
      "source": [
        "!python attack_networks.py --model=fullBNN --model_idx=0 \\\n",
        "\t\t--attack_method=fgsm --n_inputs=500"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "PyTorch Version:  1.7.0\n",
            "\n",
            "Loading mnist.\n",
            "x_train shape = torch.Size([500, 1, 28, 28]) \n",
            "x_test shape = torch.Size([500, 1, 28, 28])\n",
            "y_train shape = torch.Size([500, 10]) \n",
            "y_test shape = torch.Size([500, 10])\n",
            "\n",
            "baseNN total number of weights = 456618\n",
            "\n",
            "Loading  ../experiments/fullBNN/mnist_conv_idx=0/mnist_fullBNN_svi_hid=512_act=leaky_arch=conv_ep=5_lr=0.01_weights.pt\n",
            "\n",
            "\n",
            "Crafting fgsm attacks\n",
            "  0% 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/pyro/primitives.py:406: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n",
            "100% 500/500 [00:38<00:00, 13.08it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/attacks/fgsm_attackSamp=10_attack.pkl\n",
            "\n",
            "Evaluating against the attacks with 10 defense samples\n",
            "\n",
            "test accuracy = 89.4\tadversarial accuracy = 71.6\tavg softmax robustness = 0.82\n",
            "\n",
            "\n",
            "Crafting fgsm attacks\n",
            "100% 500/500 [03:05<00:00,  2.70it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/attacks/fgsm_attackSamp=50_attack.pkl\n",
            "\n",
            "Evaluating against the attacks with 50 defense samples\n",
            "\n",
            "test accuracy = 91.4\tadversarial accuracy = 75.2\tavg softmax robustness = 0.82\n",
            "\n",
            "\n",
            "Crafting fgsm attacks\n",
            "100% 500/500 [00:03<00:00, 133.74it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/attacks/fgsm_mode_attack.pkl\n",
            "\n",
            "Evaluating against the attacks with the posterior mode\n",
            "\n",
            "test accuracy = 90.8\tadversarial accuracy = 85.6\tavg softmax robustness = 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmrhywK1iFRm"
      },
      "source": [
        "### LRP Computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKTZXoWI48Ha",
        "outputId": "957fdfb1-9629-44b9-8ca8-1d609102aa5d"
      },
      "source": [
        "!python compute_lrp.py --model_idx=0 --attack_method=fgsm \\\n",
        "\t\t--n_inputs=500 --rule=epsilon"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "PyTorch Version:  1.7.0\n",
            "Torchvision Version:  0.8.1\n",
            "\n",
            "Loading mnist.\n",
            "x_train shape = torch.Size([500, 1, 28, 28]) \n",
            "x_test shape = torch.Size([500, 1, 28, 28])\n",
            "y_train shape = torch.Size([500, 10]) \n",
            "y_test shape = torch.Size([500, 10])\n",
            "\n",
            "baseNN total number of weights = 456618\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/attacks/fgsm_attack.pkl\n",
            "\n",
            "baseNN total number of weights = 456618\n",
            "\n",
            "Loading  ../experiments/fullBNN/mnist_conv_idx=0/mnist_fullBNN_svi_hid=512_act=leaky_arch=conv_ep=5_lr=0.01_weights.pt\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/attacks/fgsm_attackSamp=10_attack.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/attacks/fgsm_attackSamp=50_attack.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/attacks/fgsm_mode_attack.pkl\n",
            "\n",
            "LRP layer idx = 0\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [00:00<00:00, 767.68it/s]\n",
            "\n",
            "LRP layer idx = 0\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [00:00<00:00, 785.34it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=0/det_lrp.pkl\n",
            "\n",
            "Saving pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=0/det_attack_lrp.pkl\n",
            "\n",
            "LRP layer idx = 0\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "  0% 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/pyro/primitives.py:406: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n",
            "100% 500/500 [00:30<00:00, 16.61it/s]\n",
            "\n",
            "LRP layer idx = 0\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [00:30<00:00, 16.53it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_lrp_samp=10.pkl\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_attack_lrp_samp=10.pkl\n",
            "\n",
            "LRP layer idx = 0\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [02:28<00:00,  3.36it/s]\n",
            "\n",
            "LRP layer idx = 0\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [02:28<00:00,  3.38it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_lrp_samp=50.pkl\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_attack_lrp_samp=50.pkl\n",
            "\n",
            "LRP layer idx = 0\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [00:02<00:00, 173.37it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/mode_lrp_avg_post.pkl\n",
            "\n",
            "LRP layer idx = 0\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [00:29<00:00, 16.74it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/mode_attack_lrp_samp=10.pkl\n",
            "\n",
            "LRP layer idx = 0\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [02:28<00:00,  3.37it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/mode_attack_lrp_samp=50.pkl\n",
            "\n",
            "LRP layer idx = 0\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [00:02<00:00, 173.11it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/mode_attack_lrp_avg_post.pkl\n",
            "\n",
            "LRP layer idx = 3\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [00:00<00:00, 533.68it/s]\n",
            "\n",
            "LRP layer idx = 3\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [00:00<00:00, 536.64it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=3/det_lrp.pkl\n",
            "\n",
            "Saving pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=3/det_attack_lrp.pkl\n",
            "\n",
            "LRP layer idx = 3\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [00:33<00:00, 15.09it/s]\n",
            "\n",
            "LRP layer idx = 3\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [00:32<00:00, 15.39it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_lrp_samp=10.pkl\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_attack_lrp_samp=10.pkl\n",
            "\n",
            "LRP layer idx = 3\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [02:43<00:00,  3.06it/s]\n",
            "\n",
            "LRP layer idx = 3\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [02:42<00:00,  3.07it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_lrp_samp=50.pkl\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_attack_lrp_samp=50.pkl\n",
            "\n",
            "LRP layer idx = 3\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [00:03<00:00, 154.47it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/mode_lrp_avg_post.pkl\n",
            "\n",
            "LRP layer idx = 3\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [00:32<00:00, 15.20it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/mode_attack_lrp_samp=10.pkl\n",
            "\n",
            "LRP layer idx = 3\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [02:43<00:00,  3.06it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/mode_attack_lrp_samp=50.pkl\n",
            "\n",
            "LRP layer idx = 3\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "100% 500/500 [00:03<00:00, 156.16it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/mode_attack_lrp_avg_post.pkl\n",
            "\n",
            "LRP layer idx = 7\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): LeakyReLU(negative_slope=0.01)\n",
            "  (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  (7): Linear(in_features=25088, out_features=10, bias=True)\n",
            ")\n",
            "100% 500/500 [00:01<00:00, 422.96it/s]\n",
            "\n",
            "LRP layer idx = 7\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): LeakyReLU(negative_slope=0.01)\n",
            "  (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  (7): Linear(in_features=25088, out_features=10, bias=True)\n",
            ")\n",
            "100% 500/500 [00:01<00:00, 421.11it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=7/det_lrp.pkl\n",
            "\n",
            "Saving pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=7/det_attack_lrp.pkl\n",
            "\n",
            "LRP layer idx = 7\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): LeakyReLU(negative_slope=0.01)\n",
            "  (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  (7): Linear(in_features=25088, out_features=10, bias=True)\n",
            ")\n",
            "100% 500/500 [00:35<00:00, 14.21it/s]\n",
            "\n",
            "LRP layer idx = 7\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): LeakyReLU(negative_slope=0.01)\n",
            "  (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  (7): Linear(in_features=25088, out_features=10, bias=True)\n",
            ")\n",
            "100% 500/500 [00:34<00:00, 14.33it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_lrp_samp=10.pkl\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_attack_lrp_samp=10.pkl\n",
            "\n",
            "LRP layer idx = 7\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): LeakyReLU(negative_slope=0.01)\n",
            "  (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  (7): Linear(in_features=25088, out_features=10, bias=True)\n",
            ")\n",
            "100% 500/500 [02:54<00:00,  2.87it/s]\n",
            "\n",
            "LRP layer idx = 7\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): LeakyReLU(negative_slope=0.01)\n",
            "  (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  (7): Linear(in_features=25088, out_features=10, bias=True)\n",
            ")\n",
            "100% 500/500 [02:53<00:00,  2.89it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_lrp_samp=50.pkl\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_attack_lrp_samp=50.pkl\n",
            "\n",
            "LRP layer idx = 7\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): LeakyReLU(negative_slope=0.01)\n",
            "  (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  (7): Linear(in_features=25088, out_features=10, bias=True)\n",
            ")\n",
            "100% 500/500 [00:03<00:00, 145.88it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/mode_lrp_avg_post.pkl\n",
            "\n",
            "LRP layer idx = 7\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): LeakyReLU(negative_slope=0.01)\n",
            "  (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  (7): Linear(in_features=25088, out_features=10, bias=True)\n",
            ")\n",
            "100% 500/500 [00:35<00:00, 14.16it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/mode_attack_lrp_samp=10.pkl\n",
            "\n",
            "LRP layer idx = 7\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): LeakyReLU(negative_slope=0.01)\n",
            "  (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  (7): Linear(in_features=25088, out_features=10, bias=True)\n",
            ")\n",
            "100% 500/500 [02:53<00:00,  2.89it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/mode_attack_lrp_samp=50.pkl\n",
            "\n",
            "LRP layer idx = 7\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.01)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): LeakyReLU(negative_slope=0.01)\n",
            "  (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  (7): Linear(in_features=25088, out_features=10, bias=True)\n",
            ")\n",
            "100% 500/500 [00:03<00:00, 146.07it/s]\n",
            "\n",
            "Saving pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/mode_attack_lrp_avg_post.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnnfu8kMiz5N"
      },
      "source": [
        "### LRP Heatmaps of  Determinnant NN vs Bayesian NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XFnTnTE5oq9",
        "outputId": "df761253-1126-453c-b0a6-e6aafb4e415d"
      },
      "source": [
        "!python lrp_heatmaps_det_vs_bay.py --n_inputs=500 --model_idx=0 \\\n",
        "\t\t--topk=100 --n_samples=50 --attack_method=fgsm --lrp_method=avg_heatmap "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "PyTorch Version:  1.7.0\n",
            "Torchvision Version:  0.8.1\n",
            "\n",
            "Loading mnist.\n",
            "x_train shape = torch.Size([500, 1, 28, 28]) \n",
            "x_test shape = torch.Size([500, 1, 28, 28])\n",
            "y_train shape = torch.Size([500, 10]) \n",
            "y_test shape = torch.Size([500, 10])\n",
            "\n",
            "baseNN total number of weights = 456618\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/attacks/fgsm_attack.pkl\n",
            "\n",
            "Evaluating against the attacks\n",
            "test accuracy = 98.6\tadversarial accuracy = 29.6\tavg softmax robustness = 0.32\n",
            "\n",
            "Loading mnist.\n",
            "x_train shape = torch.Size([500, 1, 28, 28]) \n",
            "x_test shape = torch.Size([500, 1, 28, 28])\n",
            "y_train shape = torch.Size([500, 10]) \n",
            "y_test shape = torch.Size([500, 10])\n",
            "\n",
            "baseNN total number of weights = 456618\n",
            "\n",
            "Loading  ../experiments/fullBNN/mnist_conv_idx=0/mnist_fullBNN_svi_hid=512_act=leaky_arch=conv_ep=5_lr=0.01_weights.pt\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/attacks/fgsm_attackSamp=50_attack.pkl\n",
            "\n",
            "Evaluating against the attacks with 50 defense samples\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/primitives.py:406: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n",
            "\n",
            "test accuracy = 91.0\tadversarial accuracy = 75.2\tavg softmax robustness = 0.67\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=7/det_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=7/det_attack_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_lrp_samp=50.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_attack_lrp_samp=50.pkl\n",
            "det LRP robustness = 0.38\n",
            "bay LRP robustness = 0.45\n",
            "relevant pixels= [array([  5,   4,   6,   7,  23,  22,  20,  21,  17,  16,  18,  19,  27,\n",
            "        26,  24,  25,  29,  28,  30,  31, 119, 118, 116, 117, 113, 112,\n",
            "       114, 107,  99,  98,  96,  97, 101, 100, 102, 103, 123, 122, 120,\n",
            "       121, 125, 124, 126, 115, 324, 236, 575, 268, 658, 576, 545, 517,\n",
            "       208, 629, 463, 603, 155, 601, 688, 631, 379, 660, 461, 659, 436,\n",
            "       323, 321, 408, 351, 407, 183, 630, 491, 632, 574, 294, 433, 435,\n",
            "       378, 405, 265, 462, 377, 210, 154, 406, 211, 546, 237, 322, 293,\n",
            "       490, 238, 266, 153, 518, 434, 182, 181, 209])]\n",
            "relevant pixels= [array([370, 422,  79, 557, 622, 256, 536, 500, 720, 537, 529, 107, 402,\n",
            "       239, 368, 539, 480, 481, 386, 230, 556, 458, 637,  90, 522, 527,\n",
            "       555, 497, 528, 571, 714, 486, 636, 499, 540, 713, 426, 601, 424,\n",
            "       440, 554, 384, 385, 208, 352, 688, 541, 410, 687, 127, 498, 526,\n",
            "       286, 573, 577, 578, 576, 408, 411, 377, 659, 351, 492, 542, 604,\n",
            "       436, 660, 686, 323, 632, 405, 407, 265, 211, 489, 295, 321, 491,\n",
            "       435, 154, 349, 322, 462, 293, 350, 266, 153, 294, 490, 406, 182,\n",
            "       434, 267, 237, 546, 181, 518, 238, 210, 209])]\n",
            "relevant pixels= [array([101,   4,   6,   7,  23,  22,  20,  21,  17,  16,  18,  19,  27,\n",
            "        26,  24,  25,  29,  28,  30,  31, 119, 118, 116, 117, 113, 112,\n",
            "       114, 115, 123, 122, 120, 121, 125, 100, 102, 103, 264, 267, 209,\n",
            "       268, 576, 574, 547, 520, 491, 575, 548, 546, 518, 237, 295, 462,\n",
            "       323, 238, 435, 464, 492, 436, 519, 265, 293, 463, 351, 266, 379,\n",
            "       407, 490, 236, 632, 434, 349, 350, 321, 406, 378, 322, 294, 211,\n",
            "       210, 377, 405, 602, 380, 688, 181, 433, 182, 603, 180, 631, 657,\n",
            "       376, 629, 154, 687, 573, 183, 461, 686, 153])]\n",
            "relevant pixels= [array([620, 439, 237, 380, 323, 660, 507, 463, 563, 490, 633, 436, 482,\n",
            "       452, 592, 151, 149, 662, 174,  92,  94, 379, 650, 680, 358, 652,\n",
            "       564, 654, 238, 351, 122, 150, 407, 651, 623, 145, 605, 634, 119,\n",
            "       175, 622, 266, 293, 408, 624, 205, 434, 144, 229, 621, 580, 203,\n",
            "       232, 178, 173, 207,  91, 349, 627, 606, 200, 172, 294, 350, 406,\n",
            "       378, 202, 257, 596, 321, 120, 148, 322, 201, 594, 147, 176, 377,\n",
            "       211, 210, 405, 602, 433, 658, 603, 657, 376, 180, 687, 688, 629,\n",
            "       631, 181, 154, 182, 573, 686, 183, 153, 461])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POVUvaKhi8sC"
      },
      "source": [
        "### LRP Heatmaps between Different Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t3dy0ZV51-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e9bb9f-6d2e-4107-b83f-171cea5d566a"
      },
      "source": [
        "!python lrp_heatmaps_layers.py --model=baseNN --model_idx=0 \\\n",
        "\t\t--n_inputs=500 --topk=100 --n_samples=50 --attack_method=fgsm \\\n",
        "\t\t--lrp_method=avg_heatmap --normalize=True"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "PyTorch Version:  1.7.0\n",
            "Torchvision Version:  0.8.1\n",
            "\n",
            "Loading mnist.\n",
            "x_train shape = torch.Size([500, 1, 28, 28]) \n",
            "x_test shape = torch.Size([500, 1, 28, 28])\n",
            "y_train shape = torch.Size([500, 10]) \n",
            "y_test shape = torch.Size([500, 10])\n",
            "\n",
            "baseNN total number of weights = 456618\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/attacks/fgsm_attack.pkl\n",
            "\n",
            "Evaluating against the attacks\n",
            "test accuracy = 98.6\tadversarial accuracy = 29.6\tavg softmax robustness = 0.32\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=0/det_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=0/det_attack_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=3/det_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=3/det_attack_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=7/det_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=7/det_attack_lrp.pkl\n",
            "im_idx = [252]\n",
            "relevant pixels= [array([151, 152, 153, 154, 155, 178, 179, 180, 181, 182, 183, 184, 185,\n",
            "       205, 206, 210, 211, 212, 213, 232, 233, 260, 288, 289, 297, 298,\n",
            "       299, 316, 317, 322, 323, 324, 325, 326, 327, 349, 350, 351, 355,\n",
            "       373, 374, 375, 376, 384, 385, 412, 413, 440, 441, 468, 469, 568,\n",
            "       569, 581, 596, 597, 598, 608, 609, 626, 636, 655, 656, 657, 658,\n",
            "       659, 662, 663, 664, 685, 686, 687, 689, 690])]\n",
            "relevant pixels= [array([151, 152, 153, 154, 155, 178, 179, 180, 181, 182, 183, 184, 185,\n",
            "       205, 206, 210, 211, 212, 213, 232, 233, 260, 288, 289, 297, 298,\n",
            "       299, 316, 317, 322, 323, 324, 325, 326, 327, 349, 350, 351, 355,\n",
            "       373, 374, 375, 376, 384, 385, 412, 413, 440, 441, 468, 469, 568,\n",
            "       569, 581, 596, 597, 598, 608, 609, 626, 636, 655, 656, 657, 658,\n",
            "       659, 662, 663, 664, 685, 686, 687, 689, 690])]\n",
            "\n",
            "Layer idx= 0\n",
            "explanations min=-0.054746270179748535 max=1.0\n",
            "attack_explanations min=-0.35595929622650146 max=1.0\n",
            "relevant pixels= [array([153, 154, 155, 178, 181, 182, 183, 184, 205, 206, 210, 212, 232,\n",
            "       233, 296, 297, 298, 317, 323, 324, 325, 327, 345, 346, 348, 349,\n",
            "       350, 351, 355, 356, 373, 374, 375, 376, 377, 384, 403, 412, 413,\n",
            "       440, 441, 468, 469, 496, 497, 525, 553, 568, 569, 581, 596, 597,\n",
            "       598, 599, 625, 626, 627, 635, 636, 654, 655, 656, 657, 662, 663,\n",
            "       685])]\n",
            "relevant pixels= [array([153, 154, 155, 178, 181, 182, 183, 184, 205, 206, 210, 212, 232,\n",
            "       233, 296, 297, 298, 317, 323, 324, 325, 327, 345, 346, 348, 349,\n",
            "       350, 351, 355, 356, 373, 374, 375, 376, 377, 384, 403, 412, 413,\n",
            "       440, 441, 468, 469, 496, 497, 525, 553, 568, 569, 581, 596, 597,\n",
            "       598, 599, 625, 626, 627, 635, 636, 654, 655, 656, 657, 662, 663,\n",
            "       685])]\n",
            "\n",
            "Layer idx= 1\n",
            "explanations min=-0.5284256339073181 max=1.0\n",
            "attack_explanations min=-0.5680039525032043 max=1.0\n",
            "relevant pixels= [array([151, 152, 153, 154, 155, 177, 178, 179, 180, 182, 183, 184, 205,\n",
            "       211, 233, 260, 261, 289, 296, 317, 322, 324, 325, 344, 345, 346,\n",
            "       349, 350, 373, 374, 375, 376, 401, 403, 412, 413, 440, 441, 469,\n",
            "       497, 553, 581, 596, 598])]\n",
            "relevant pixels= [array([151, 152, 153, 154, 155, 177, 178, 179, 180, 182, 183, 184, 205,\n",
            "       211, 233, 260, 261, 289, 296, 317, 322, 324, 325, 344, 345, 346,\n",
            "       349, 350, 373, 374, 375, 376, 401, 403, 412, 413, 440, 441, 469,\n",
            "       497, 553, 581, 596, 598])]\n",
            "\n",
            "Layer idx= 2\n",
            "explanations min=-0.7912596464157104 max=1.0\n",
            "attack_explanations min=-0.6309014558792114 max=1.0\n",
            "relevant pixels= [array([151, 152, 153, 154, 155, 178, 179, 180, 181, 182, 183, 184, 185,\n",
            "       205, 206, 210, 211, 212, 213, 232, 233, 260, 288, 289, 297, 298,\n",
            "       299, 316, 317, 322, 323, 324, 325, 326, 327, 349, 350, 351, 355,\n",
            "       373, 374, 375, 376, 384, 385, 412, 413, 440, 441, 468, 469, 568,\n",
            "       569, 581, 596, 597, 598, 608, 609, 626, 636, 655, 656, 657, 658,\n",
            "       659, 662, 663, 664, 685, 686, 687, 689, 690])]\n",
            "relevant pixels= [array([151, 152, 153, 154, 155, 178, 179, 180, 181, 182, 183, 184, 185,\n",
            "       205, 206, 210, 211, 212, 213, 232, 233, 260, 288, 289, 297, 298,\n",
            "       299, 316, 317, 322, 323, 324, 325, 326, 327, 349, 350, 351, 355,\n",
            "       373, 374, 375, 376, 384, 385, 412, 413, 440, 441, 468, 469, 568,\n",
            "       569, 581, 596, 597, 598, 608, 609, 626, 636, 655, 656, 657, 658,\n",
            "       659, 662, 663, 664, 685, 686, 687, 689, 690])]\n",
            "relevant pixels= [array([153, 154, 155, 178, 181, 182, 183, 184, 205, 206, 210, 212, 232,\n",
            "       233, 296, 297, 298, 317, 323, 324, 325, 327, 345, 346, 348, 349,\n",
            "       350, 351, 355, 356, 373, 374, 375, 376, 377, 384, 403, 412, 413,\n",
            "       440, 441, 468, 469, 496, 497, 525, 553, 568, 569, 581, 596, 597,\n",
            "       598, 599, 625, 626, 627, 635, 636, 654, 655, 656, 657, 662, 663,\n",
            "       685])]\n",
            "relevant pixels= [array([153, 154, 155, 178, 181, 182, 183, 184, 205, 206, 210, 212, 232,\n",
            "       233, 296, 297, 298, 317, 323, 324, 325, 327, 345, 346, 348, 349,\n",
            "       350, 351, 355, 356, 373, 374, 375, 376, 377, 384, 403, 412, 413,\n",
            "       440, 441, 468, 469, 496, 497, 525, 553, 568, 569, 581, 596, 597,\n",
            "       598, 599, 625, 626, 627, 635, 636, 654, 655, 656, 657, 662, 663,\n",
            "       685])]\n",
            "relevant pixels= [array([151, 152, 153, 154, 155, 177, 178, 179, 180, 182, 183, 184, 205,\n",
            "       211, 233, 260, 261, 289, 296, 317, 322, 324, 325, 344, 345, 346,\n",
            "       349, 350, 373, 374, 375, 376, 401, 403, 412, 413, 440, 441, 469,\n",
            "       497, 553, 581, 596, 598])]\n",
            "relevant pixels= [array([151, 152, 153, 154, 155, 177, 178, 179, 180, 182, 183, 184, 205,\n",
            "       211, 233, 260, 261, 289, 296, 317, 322, 324, 325, 344, 345, 346,\n",
            "       349, 350, 373, 374, 375, 376, 401, 403, 412, 413, 440, 441, 469,\n",
            "       497, 553, 581, 596, 598])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2Ys5zXkjb4W"
      },
      "source": [
        "## Calculate LRP Robustness of Bayesian NN with FGSM Attacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGiIf08L6Sri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d60d04e1-2b2e-44af-82dc-dc9080a4d3fa"
      },
      "source": [
        "!python lrp_layers_robustness.py --n_inputs=500 --model_idx=0 \\\n",
        "\t\t--model=fullBNN --attack_method=fgsm --rule=epsilon"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "PyTorch Version:  1.7.0\n",
            "Torchvision Version:  0.8.1\n",
            "\n",
            "Loading mnist.\n",
            "x_train shape = torch.Size([500, 1, 28, 28]) \n",
            "x_test shape = torch.Size([500, 1, 28, 28])\n",
            "y_train shape = torch.Size([500, 10]) \n",
            "y_test shape = torch.Size([500, 10])\n",
            "\n",
            "baseNN total number of weights = 456618\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/attacks/fgsm_attack.pkl\n",
            "\n",
            "baseNN total number of weights = 456618\n",
            "\n",
            "Loading  ../experiments/fullBNN/mnist_conv_idx=0/mnist_fullBNN_svi_hid=512_act=leaky_arch=conv_ep=5_lr=0.01_weights.pt\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/attacks/fgsm_attackSamp=10_attack.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/attacks/fgsm_attackSamp=50_attack.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=0/det_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=0/det_attack_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_attack_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_lrp_samp=50.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_attack_lrp_samp=50.pkl\n",
            "\n",
            "Evaluating against the attacks\n",
            "test accuracy = 98.6\tadversarial accuracy = 29.6\tavg softmax robustness = 0.32\n",
            "\n",
            "Evaluating against the attacks with 10 defense samples\n",
            "/usr/local/lib/python3.7/dist-packages/pyro/primitives.py:406: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n",
            "\n",
            "test accuracy = 89.4\tadversarial accuracy = 71.6\tavg softmax robustness = 0.82\n",
            "\n",
            "Evaluating against the attacks with 50 defense samples\n",
            "\n",
            "test accuracy = 91.4\tadversarial accuracy = 75.2\tavg softmax robustness = 0.82\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=3/det_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=3/det_attack_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_attack_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_lrp_samp=50.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_attack_lrp_samp=50.pkl\n",
            "\n",
            "Evaluating against the attacks\n",
            "test accuracy = 98.6\tadversarial accuracy = 29.6\tavg softmax robustness = 0.32\n",
            "\n",
            "Evaluating against the attacks with 10 defense samples\n",
            "\n",
            "test accuracy = 89.4\tadversarial accuracy = 71.6\tavg softmax robustness = 0.82\n",
            "\n",
            "Evaluating against the attacks with 50 defense samples\n",
            "\n",
            "test accuracy = 91.4\tadversarial accuracy = 75.2\tavg softmax robustness = 0.82\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=7/det_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=7/det_attack_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_attack_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_lrp_samp=50.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_attack_lrp_samp=50.pkl\n",
            "\n",
            "Evaluating against the attacks\n",
            "test accuracy = 98.6\tadversarial accuracy = 29.6\tavg softmax robustness = 0.32\n",
            "\n",
            "Evaluating against the attacks with 10 defense samples\n",
            "\n",
            "test accuracy = 89.4\tadversarial accuracy = 71.6\tavg softmax robustness = 0.82\n",
            "\n",
            "Evaluating against the attacks with 50 defense samples\n",
            "\n",
            "test accuracy = 91.4\tadversarial accuracy = 75.2\tavg softmax robustness = 0.82\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=0/det_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=0/det_attack_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_attack_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_lrp_samp=50.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_attack_lrp_samp=50.pkl\n",
            "\n",
            "Evaluating against the attacks\n",
            "test accuracy = 98.6\tadversarial accuracy = 29.6\tavg softmax robustness = 0.32\n",
            "\n",
            "Evaluating against the attacks with 10 defense samples\n",
            "\n",
            "test accuracy = 89.4\tadversarial accuracy = 71.6\tavg softmax robustness = 0.82\n",
            "\n",
            "Evaluating against the attacks with 50 defense samples\n",
            "\n",
            "test accuracy = 91.4\tadversarial accuracy = 75.2\tavg softmax robustness = 0.82\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=3/det_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=3/det_attack_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_attack_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_lrp_samp=50.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_attack_lrp_samp=50.pkl\n",
            "\n",
            "Evaluating against the attacks\n",
            "test accuracy = 98.6\tadversarial accuracy = 29.6\tavg softmax robustness = 0.32\n",
            "\n",
            "Evaluating against the attacks with 10 defense samples\n",
            "\n",
            "test accuracy = 89.4\tadversarial accuracy = 71.6\tavg softmax robustness = 0.82\n",
            "\n",
            "Evaluating against the attacks with 50 defense samples\n",
            "\n",
            "test accuracy = 91.4\tadversarial accuracy = 75.2\tavg softmax robustness = 0.82\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=7/det_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=7/det_attack_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_attack_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_lrp_samp=50.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_attack_lrp_samp=50.pkl\n",
            "\n",
            "Evaluating against the attacks\n",
            "test accuracy = 98.6\tadversarial accuracy = 29.6\tavg softmax robustness = 0.32\n",
            "\n",
            "Evaluating against the attacks with 10 defense samples\n",
            "\n",
            "test accuracy = 89.4\tadversarial accuracy = 71.6\tavg softmax robustness = 0.82\n",
            "\n",
            "Evaluating against the attacks with 50 defense samples\n",
            "\n",
            "test accuracy = 91.4\tadversarial accuracy = 75.2\tavg softmax robustness = 0.82\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=0/det_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=0/det_attack_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_attack_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_lrp_samp=50.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=0/bay_attack_lrp_samp=50.pkl\n",
            "\n",
            "Evaluating against the attacks\n",
            "test accuracy = 98.6\tadversarial accuracy = 29.6\tavg softmax robustness = 0.32\n",
            "\n",
            "Evaluating against the attacks with 10 defense samples\n",
            "\n",
            "test accuracy = 89.4\tadversarial accuracy = 71.6\tavg softmax robustness = 0.82\n",
            "\n",
            "Evaluating against the attacks with 50 defense samples\n",
            "\n",
            "test accuracy = 91.4\tadversarial accuracy = 75.2\tavg softmax robustness = 0.82\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=3/det_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=3/det_attack_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_attack_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_lrp_samp=50.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=3/bay_attack_lrp_samp=50.pkl\n",
            "\n",
            "Evaluating against the attacks\n",
            "test accuracy = 98.6\tadversarial accuracy = 29.6\tavg softmax robustness = 0.32\n",
            "\n",
            "Evaluating against the attacks with 10 defense samples\n",
            "\n",
            "test accuracy = 89.4\tadversarial accuracy = 71.6\tavg softmax robustness = 0.82\n",
            "\n",
            "Evaluating against the attacks with 50 defense samples\n",
            "\n",
            "test accuracy = 91.4\tadversarial accuracy = 75.2\tavg softmax robustness = 0.82\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=7/det_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/baseNN/mnist_conv_idx=0/fgsm/lrp/pkl_layer_idx=7/det_attack_lrp.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_attack_lrp_samp=10.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_lrp_samp=50.pkl\n",
            "\n",
            "Loading from pickle:  ../experiments/fullBNN/mnist_conv_idx=0/fgsm/avg_heatmap_lrp/pkl_layer_idx=7/bay_attack_lrp_samp=50.pkl\n",
            "\n",
            "Evaluating against the attacks\n",
            "test accuracy = 98.6\tadversarial accuracy = 29.6\tavg softmax robustness = 0.32\n",
            "\n",
            "Evaluating against the attacks with 10 defense samples\n",
            "\n",
            "test accuracy = 89.4\tadversarial accuracy = 71.6\tavg softmax robustness = 0.82\n",
            "\n",
            "Evaluating against the attacks with 50 defense samples\n",
            "\n",
            "test accuracy = 91.4\tadversarial accuracy = 75.2\tavg softmax robustness = 0.82\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJgZCwILjtVN"
      },
      "source": [
        "Heatmaps, weights and models will be saved under the `experiments` folder"
      ]
    }
  ]
}